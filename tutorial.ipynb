{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Med-BERT\n",
    "Step-by-step guide to the PyTorch implementation of [Med-BERT](https://www.nature.com/articles/s41746-021-00455-y) \n",
    "\n",
    "<sub><sup><em>\"Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction.\" NPJ digital medicine 4.1 (2021): 1-13., Rasmy, Laila, et al. <em><sub><sup>\n",
    "\n",
    "------------------------------------------\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of Med-Bert is to obtain good representations of elctronic health records (EHR) to make predicitons for downstream tasks. <br>\n",
    "In order to do so we leverage the power of the pretraining fine-tuning paradigm using a transformer architecture $^{1}$.  \n",
    "Originally used for Natural Language Processing, the transformers have proven their universality by showing SoTA results in fields like computer vision $^2$ and speech recognition $^3$. <br>\n",
    "Recently, a variant of the transformers, called BERT $^{4}$ has also been applied to medical data and electronic health records in particular $^{5-7}$.<br> \n",
    "There are countless tutorials that explain the theory and basic concepts behind the Transformers and BERT as well as their applicaiton to NLP, so here we will focus on using BERT for EHR specifically.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "A toy dataset is stored in data/processed/pretrain/synthea500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# used to create configs\n",
    "class DotDict(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        return self[attr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "In this step we simply assign integers to each unique code and bring all sequences to the same length to pass data as a tensor.<br>\n",
    "Alternatively, we can use dynamic padding during training. The advantage of this is that we pad to the longest sequence in the batch instead of the longest sequence in the data. Because the sequence length contributes quadratically to training time this can accelerate training.<br>\n",
    "Additional tokens are needed to Mask inputs and to take care of new codes that are not in the vocab dictionary that might appear in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are stored in a dictionary. Inside that dictionary we have a list of lists, where every inner list is a patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['314529007', '314529007', '314529007', '314529007', '314529007', '314529007', '314529007', '314529007', '314529007', '314529007', '314529007', '314529007']\n"
     ]
    }
   ],
   "source": [
    "train_features = torch.load(\"data/processed/pretrain/synthea500/train.pt\")\n",
    "val_features = torch.load(\"data/processed/pretrain/synthea500/val.pt\")\n",
    "print(val_features['concept'][4][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding patients: 391it [00:00, 4035.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  5,  6,  4,  6,  7,  4,  8,  9,  4,  9,  4,  7,  9,  4,  9,  6,  4,\n",
      "          9,  4,  9,  4,  9,  4,  9,  4,  9, 10,  4,  9,  4,  9,  4, 11,  9,  4,\n",
      "          9, 12,  6,  4, 13,  9, 10,  4,  9,  7,  4, 11,  9,  4,  6, 11,  9,  4,\n",
      "          9, 14,  4, 11,  7,  9,  4, 15, 16, 17, 18, 19,  4,  9,  6,  4, 11, 20,\n",
      "          9,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 3, 21,  4,  5,  7,  4, 10,  7,  4, 22,  4,  7,  4, 23, 24, 20,  4, 25,\n",
      "          4, 26,  4,  6,  4, 27, 28, 29, 30,  4, 11, 27, 12,  4, 11, 27,  4, 11,\n",
      "         27,  4, 11, 27,  4, 27, 11,  6,  4, 11, 31, 27,  4, 11, 27,  4, 32, 33,\n",
      "         34,  4, 27, 12,  6,  4, 27, 35,  4, 36,  4, 37, 38, 39,  4, 27, 11,  4,\n",
      "         36,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 3, 40,  9, 41, 42, 11, 43, 14,  4, 44,  9, 41, 42, 13,  6,  4, 31,  7,\n",
      "         11, 41, 42,  9, 44,  4,  9, 42, 41, 44, 45,  4, 13, 44, 41,  9, 42,  4,\n",
      "         44, 42, 41,  9, 11, 14,  6,  4, 42, 44, 41, 11,  9, 43,  4, 11, 44, 41,\n",
      "         42,  9,  7, 31,  4,  9, 44, 42, 41, 11,  6,  4, 11,  9, 44, 42, 41, 13,\n",
      "          4, 44, 41, 42,  9,  7, 11,  4, 44, 41, 42,  9, 11,  4, 44,  9, 41, 42,\n",
      "         46, 11,  4, 47, 48, 49, 50,  4, 51,  4]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from medbert.features.tokenizer import EHRTokenizer\n",
    "tokenizer_config = DotDict({\n",
    "    'sep_tokens': True, # should we add [SEP] tokens?\n",
    "    'cls_token': True, # should we add a [CLS] token?\n",
    "    'padding': True, # should we pad the sequences?\n",
    "    'truncation': 100}) # how long should the longest sequence be\n",
    "tokenizer = EHRTokenizer(config=tokenizer_config)\n",
    "train_tokenized = tokenizer(train_features) \n",
    "print(train_tokenized['concept'][:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tokenizing the train set, one should freeze and save the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[MASK]': 1, '[UNK]': 2, '[CLS]': 3, '[SEP]': 4, '224299000': 5, '73595000': 6, '160903007': 7, '59621000': 8, '314076': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding patients: 112it [00:00, 3881.08it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.freeze_vocabulary()\n",
    "# tokenizer.save_vocab(\"../output/vocabulary.pt\")\n",
    "print({k:v for k,v in tokenizer.vocabulary.items() if v < 10})\n",
    "# Now we tokenize the validation set:\n",
    "val_tokenized = tokenizer(val_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset takes care of multiple things:\n",
    "* masking input tokens and creating an appropriate target\n",
    "* constructing an attention mask to ignore padding tokens \n",
    "* It allows the model to get an item (patient) via __getitem__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medbert.features import dataset\n",
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "\n",
    "dataset_config = DotDict({\n",
    "    'masked_ratio': 0.99, # 0.15 usually\n",
    "    'ignore_special_tokens': True,\n",
    "})\n",
    "\n",
    "train_dataset = dataset.MLM_PLOS_Dataset(train_tokenized, vocabulary=tokenizer.vocabulary, dataset_config=dataset_config, min_los=3, masked_ratio=0.8)\n",
    "val_dataset = dataset.MLM_PLOS_Dataset(val_tokenized, vocabulary=tokenizer.vocabulary, dataset_config=dataset_config, min_los=3, masked_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocabulary['[MASK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  5,  6,  4,  6,  7,  4,  8,  9,  4,  9,  4,  7,  9,  4,  9,  6,  4,\n",
       "         9,  4,  9,  4,  9,  4,  9,  4,  9, 10,  4,  9,  4,  9,  4, 11,  9,  4,\n",
       "         9, 12,  6,  4, 13,  9, 10,  4,  9,  7,  4, 11,  9,  4,  6, 11,  9,  4,\n",
       "         9, 14,  4, 11,  7,  9,  4, 15, 16, 17, 18, 19,  4,  9,  6,  4, 11, 20,\n",
       "         9,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized['concept'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sample =train_dataset[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3,   1,   1,   4,   1,   7,   4,   8,   1,   4,   1,   4,   1,   1,\n",
       "          4,   9, 277,   4,   1,   4,   1,   4,   9,   4,   1,   4,   1,   1,\n",
       "          4, 286,   4,  70,   4,  11,   9,   4,   9,   1,   6,   4,   1,   1,\n",
       "        216,   4,   1,   1,   4,   1,   1,   4,   1,   1,   1,   4,   1,   1,\n",
       "          4,  11,   1, 236,   4,   1,   1,   1,   1,   1,   4,   1,   1,   4,\n",
       "         11,   1,   1,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sample['concept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  6,  6,  9,  9,  7,  9,  9,  9,  9,  9, 10, 12, 13,  9,  9,  7, 11,\n",
      "         9,  6, 11,  9,  9, 14,  7, 15, 16, 17, 18, 19,  9,  6, 20,  9])\n"
     ]
    }
   ],
   "source": [
    "mask_mask = ds_sample['concept']==1\n",
    "print(ds_sample['target'][mask_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_masking_target(train_tokenized['concept'][0], ds_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concept': tensor([[  3,   5,   6,  ...,   0,   0,   0],\n",
       "        [  3,  21,   4,  ...,   0,   0,   0],\n",
       "        [  3,  40,   9,  ...,   4,  51,   4],\n",
       "        ...,\n",
       "        [  3, 128, 239,  ...,  39,  67,   4],\n",
       "        [  3,  11,   4,  ...,   4,   0,   0],\n",
       "        [  3,  22,   4,  ...,   0,   0,   0]]), 'age': tensor([[ 0., 19., 19.,  ...,  0.,  0.,  0.],\n",
       "        [ 0., 14., 14.,  ...,  0.,  0.,  0.],\n",
       "        [ 0., 19., 64.,  ..., 68., 68., 68.],\n",
       "        ...,\n",
       "        [ 0., 19., 32.,  ..., 49., 49., 49.],\n",
       "        [ 0.,  0.,  0.,  ..., 60.,  0.,  0.],\n",
       "        [ 0., 15., 15.,  ...,  0.,  0.,  0.]]), 'abspos': tensor([[      0.,  879144.,  879144.,  ...,       0.,       0.,       0.],\n",
       "        [      0.,  753360.,  753360.,  ...,       0.,       0.,       0.],\n",
       "        [      0.,  637104., 1037784.,  ..., 1073232., 1073376., 1073376.],\n",
       "        ...,\n",
       "        [      0.,  698568.,  813984.,  ...,  960144.,  960144.,  960144.],\n",
       "        [      0.,  548136.,  548136.,  ..., 1069944.,       0.,       0.],\n",
       "        [      0.,  536496.,  536496.,  ...,       0.,       0.,       0.]]), 'segment': tensor([[  0,   1,   1,  ...,   0,   0,   0],\n",
       "        [  0,   1,   1,  ...,   0,   0,   0],\n",
       "        [  0,   1, 100,  ..., 113, 114, 114],\n",
       "        ...,\n",
       "        [  0,   1,  17,  ...,  42,  42,  42],\n",
       "        [  0,   1,   1,  ...,  41,   0,   0],\n",
       "        [  0,   1,   1,  ...,   0,   0,   0]]), 'los': tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 2.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [0., 1., 1.,  ..., 1., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForPreTraining, BertConfig\n",
    "from torch.optim import AdamW\n",
    "\n",
    "num_attention_heads = 6\n",
    "hidden_size = num_attention_heads*10 # for parallel computation\n",
    "intermediate_size = hidden_size*4 # from original paper\n",
    "\n",
    "model = BertForPreTraining(\n",
    "        BertConfig(\n",
    "            vocab_size=len(train_dataset.vocabulary),\n",
    "            type_vocab_size=int(train_dataset.max_segments),\n",
    "            max_position_embeddings= 1024,\n",
    "            hidden_size= hidden_size,\n",
    "            num_hidden_layers= 6,\n",
    "            linear=True,\n",
    "            num_attention_heads= num_attention_heads,\n",
    "            intermediate_size= intermediate_size\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay= 0.01,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run name not provided. Using random run name: 4ab7e77e0d4f4e4a8d14267137857956\n",
      "[INFO] Run folder: ../runs\\4ab7e77e0d4f4e4a8d14267137857956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 0:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 0:  31%|███       | 4/13 [00:13<00:29,  3.28s/it, loss=6.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1: 6.64593505859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 0:  62%|██████▏   | 8/13 [00:26<00:16,  3.24s/it, loss=6.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 2: 6.6392292976379395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 0:  92%|█████████▏| 12/13 [00:35<00:02,  2.45s/it, loss=6.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 3: 6.616518497467041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 0: 100%|██████████| 13/13 [00:36<00:00,  2.81s/it, loss=6.62]\n",
      "Validation: 100%|██████████| 4/4 [00:04<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch 0 train loss: 6.123594724214994\n",
      "[INFO] Epoch 0 val loss: 6.615511775016785\n",
      "[INFO] Epoch 0 metrics: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1:  31%|███       | 4/13 [00:08<00:18,  2.08s/it, loss=6.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1: 6.607713937759399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1:  62%|██████▏   | 8/13 [00:15<00:08,  1.71s/it, loss=6.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 2: 6.594194531440735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1:  92%|█████████▏| 12/13 [00:20<00:01,  1.38s/it, loss=6.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 3: 6.57567298412323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1: 100%|██████████| 13/13 [00:21<00:00,  1.63s/it, loss=6.58]\n",
      "Validation: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch 1 train loss: 6.08540967794565\n",
      "[INFO] Epoch 1 val loss: 6.569050073623657\n",
      "[INFO] Epoch 1 metrics: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from medbert.trainer import trainer\n",
    "import importlib\n",
    "importlib.reload(trainer)\n",
    "\n",
    "ehr_trainer = trainer.EHRTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    args=DotDict({\n",
    "        'epochs': 2,\n",
    "        'batch_size': 32,\n",
    "        'effective_batch_size': 128,\n",
    "    }),\n",
    "    cfg=DotDict({'scheduler': None,\n",
    "                 'collate_fn': None,\n",
    "                 'run_name':'ptest'}))\n",
    "ehr_trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<sub><sup>[1] Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017).</sub></sup> <br>\n",
    "<sub><sup>[2] Dosovitskiy, Alexey, et al. \"An image is worth 16x16 words: Transformers for image recognition at scale.\" arXiv preprint arXiv:2010.11929 (2020).</sub></sup> <br>\n",
    "<sub><sup>[3] Polyak, Adam, et al. \"Speech resynthesis from discrete disentangled self-supervised representations.\" arXiv preprint arXiv:2104.00355 (2021).</sub></sup><br>\n",
    "<sub><sup>[4] Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018).</sub></sup><br>\n",
    "<sub><sup>[5] Li, Yikuan, et al. \"BEHRT: transformer for electronic health records.\" Scientific reports 10.1 (2020): 1-12..</sub></sup><br>\n",
    "<sub><sup>[6] Shang, Junyuan, et al. \"Pre-training of graph augmented transformers for medication recommendation.\" arXiv preprint arXiv:1906.00346 (2019).</sub></sup><br>\n",
    "<sub><sup>[7] Pang, Chao, et al. \"CEHR-BERT: Incorporating temporal information from structured EHR data to improve prediction tasks.\" Machine Learning for Health. PMLR, 2021.</sub></sup><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('medbert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d17b095f833cb6f6ab98a8b16539b4f83b513338040a731dc495c8057944685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
